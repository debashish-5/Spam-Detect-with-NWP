{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770ba926-d55e-4161-8c00-a4f4167f7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Word Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70789785-3b01-41ff-a821-64078081820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d4a478-21c5-4b50-ba9b-805e9473ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_message_dataset_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d799e65-2418-47b5-bedd-241ab6c8cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79dab25d-7896-4c03-8878-00dae26b5feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Your account has been suspended. Verify immedi...\n",
       "1                 Good morning, have a great day ahead!\n",
       "2                 Let’s catch up sometime this weekend.\n",
       "3                   Are you available for a quick call?\n",
       "4     Claim your free vacation to Hawaii. Limited ti...\n",
       "                            ...                        \n",
       "95         Can you please send me the notes from class?\n",
       "96    Congratulations! You've won a free iPhone. Cli...\n",
       "97    Hurry! Your car insurance has expired. Renew n...\n",
       "98                Let’s catch up sometime this weekend.\n",
       "99    Exclusive offer! Get 50% off on your next purc...\n",
       "Name: message, Length: 100, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780e5e21-5117-4aa4-82b7-f5f1375062c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95da03e-1a15-480a-ba0d-0f892167a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5b5ced-8380-4826-acdc-4f7d22b0f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da7d3727-292e-479f-9553-77818eea9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cf2cd3-d292-489a-b6c0-1b6a32260783",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b54c117-7a79-4f82-b29c-f86170fafb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 1,\n",
       " 'your': 2,\n",
       " 'for': 3,\n",
       " 'a': 4,\n",
       " 'free': 5,\n",
       " 'claim': 6,\n",
       " 'the': 7,\n",
       " 'get': 8,\n",
       " 'now': 9,\n",
       " 'you': 10,\n",
       " 'time': 11,\n",
       " 'been': 12,\n",
       " 'call': 13,\n",
       " 'offer': 14,\n",
       " 'win': 15,\n",
       " '1': 16,\n",
       " 'send': 17,\n",
       " 'on': 18,\n",
       " 'has': 19,\n",
       " 'click': 20,\n",
       " 'are': 21,\n",
       " 'you’ve': 22,\n",
       " 'selected': 23,\n",
       " '1000': 24,\n",
       " 'walmart': 25,\n",
       " 'gift': 26,\n",
       " 'card': 27,\n",
       " 'reply': 28,\n",
       " 'yes': 29,\n",
       " 'today': 30,\n",
       " 'available': 31,\n",
       " 'quick': 32,\n",
       " 'vacation': 33,\n",
       " 'hawaii': 34,\n",
       " 'limited': 35,\n",
       " 'please': 36,\n",
       " 'what': 37,\n",
       " 'does': 38,\n",
       " 'movie': 39,\n",
       " 'start': 40,\n",
       " 'tonight': 41,\n",
       " 'cash': 42,\n",
       " '88888': 43,\n",
       " 'and': 44,\n",
       " 'lucky': 45,\n",
       " 'lowest': 46,\n",
       " 'prices': 47,\n",
       " 'ever': 48,\n",
       " 'buy': 49,\n",
       " 'all': 50,\n",
       " 'items': 51,\n",
       " 'hurry': 52,\n",
       " 'car': 53,\n",
       " 'insurance': 54,\n",
       " 'expired': 55,\n",
       " 'renew': 56,\n",
       " 'avoid': 57,\n",
       " 'penalty': 58,\n",
       " 'good': 59,\n",
       " 'morning': 60,\n",
       " 'have': 61,\n",
       " 'great': 62,\n",
       " 'day': 63,\n",
       " 'ahead': 64,\n",
       " 'let’s': 65,\n",
       " 'catch': 66,\n",
       " 'up': 67,\n",
       " 'sometime': 68,\n",
       " 'this': 69,\n",
       " 'weekend': 70,\n",
       " 'loan': 71,\n",
       " 'is': 72,\n",
       " 'approved': 73,\n",
       " 'link': 74,\n",
       " 'proceed': 75,\n",
       " 'can': 76,\n",
       " 'me': 77,\n",
       " 'notes': 78,\n",
       " 'from': 79,\n",
       " 'class': 80,\n",
       " 'exclusive': 81,\n",
       " '50': 82,\n",
       " 'off': 83,\n",
       " 'next': 84,\n",
       " 'purchase': 85,\n",
       " 'visit': 86,\n",
       " 'our': 87,\n",
       " 'website': 88,\n",
       " 'congratulations': 89,\n",
       " \"you've\": 90,\n",
       " 'won': 91,\n",
       " 'iphone': 92,\n",
       " 'here': 93,\n",
       " 'prize': 94,\n",
       " 'i’ll': 95,\n",
       " 'once': 96,\n",
       " 'i': 97,\n",
       " 'reach': 98,\n",
       " 'home': 99,\n",
       " 'thanks': 100,\n",
       " 'help': 101,\n",
       " 'yesterday': 102,\n",
       " 'account': 103,\n",
       " 'suspended': 104,\n",
       " 'verify': 105,\n",
       " 'immediately': 106,\n",
       " 'restore': 107,\n",
       " 'access': 108,\n",
       " 'don’t': 109,\n",
       " 'forget': 110,\n",
       " 'bring': 111,\n",
       " 'book': 112,\n",
       " 'tomorrow': 113,\n",
       " 'credit': 114,\n",
       " 'score': 115,\n",
       " 'checked': 116,\n",
       " 'hey': 117,\n",
       " 'we': 118,\n",
       " 'still': 119,\n",
       " 'meeting': 120,\n",
       " 'lunch': 121,\n",
       " 'confirm': 122,\n",
       " 'attendance': 123,\n",
       " 'tomorrow’s': 124,\n",
       " 'event': 125}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f665ff5-df4e-4e82-9ab2-d09b14fba6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd41163e-1488-4a03-8da4-7471efba8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 103]\n",
      "[2, 103, 19]\n",
      "[2, 103, 19, 12]\n",
      "[2, 103, 19, 12, 104]\n",
      "[2, 103, 19, 12, 104, 105]\n",
      "[2, 103, 19, 12, 104, 105, 106]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107, 108]\n",
      "[59, 60]\n",
      "[59, 60, 61]\n",
      "[59, 60, 61, 4]\n",
      "[59, 60, 61, 4, 62]\n",
      "[59, 60, 61, 4, 62, 63]\n",
      "[59, 60, 61, 4, 62, 63, 64]\n",
      "[65, 66]\n",
      "[65, 66, 67]\n",
      "[65, 66, 67, 68]\n",
      "[65, 66, 67, 68, 69]\n",
      "[65, 66, 67, 68, 69, 70]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[2, 71]\n",
      "[2, 71, 72]\n",
      "[2, 71, 72, 73]\n",
      "[2, 71, 72, 73, 20]\n",
      "[2, 71, 72, 73, 20, 7]\n",
      "[2, 71, 72, 73, 20, 7, 74]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1, 75]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[76, 10]\n",
      "[76, 10, 36]\n",
      "[76, 10, 36, 17]\n",
      "[76, 10, 36, 17, 77]\n",
      "[76, 10, 36, 17, 77, 7]\n",
      "[76, 10, 36, 17, 77, 7, 78]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79, 80]\n",
      "[2, 71]\n",
      "[2, 71, 72]\n",
      "[2, 71, 72, 73]\n",
      "[2, 71, 72, 73, 20]\n",
      "[2, 71, 72, 73, 20, 7]\n",
      "[2, 71, 72, 73, 20, 7, 74]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1, 75]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[81, 14]\n",
      "[81, 14, 8]\n",
      "[81, 14, 8, 82]\n",
      "[81, 14, 8, 82, 83]\n",
      "[81, 14, 8, 82, 83, 18]\n",
      "[81, 14, 8, 82, 83, 18, 2]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88, 9]\n",
      "[59, 60]\n",
      "[59, 60, 61]\n",
      "[59, 60, 61, 4]\n",
      "[59, 60, 61, 4, 62]\n",
      "[59, 60, 61, 4, 62, 63]\n",
      "[59, 60, 61, 4, 62, 63, 64]\n",
      "[59, 60]\n",
      "[59, 60, 61]\n",
      "[59, 60, 61, 4]\n",
      "[59, 60, 61, 4, 62]\n",
      "[59, 60, 61, 4, 62, 63]\n",
      "[59, 60, 61, 4, 62, 63, 64]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[117, 21]\n",
      "[117, 21, 118]\n",
      "[117, 21, 118, 119]\n",
      "[117, 21, 118, 119, 120]\n",
      "[117, 21, 118, 119, 120, 3]\n",
      "[117, 21, 118, 119, 120, 3, 121]\n",
      "[117, 21, 118, 119, 120, 3, 121, 30]\n",
      "[89, 90]\n",
      "[89, 90, 91]\n",
      "[89, 90, 91, 4]\n",
      "[89, 90, 91, 4, 5]\n",
      "[89, 90, 91, 4, 5, 92]\n",
      "[89, 90, 91, 4, 5, 92, 20]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2, 94]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[95, 13]\n",
      "[95, 13, 10]\n",
      "[95, 13, 10, 96]\n",
      "[95, 13, 10, 96, 97]\n",
      "[95, 13, 10, 96, 97, 98]\n",
      "[95, 13, 10, 96, 97, 98, 99]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[59, 60]\n",
      "[59, 60, 61]\n",
      "[59, 60, 61, 4]\n",
      "[59, 60, 61, 4, 62]\n",
      "[59, 60, 61, 4, 62, 63]\n",
      "[59, 60, 61, 4, 62, 63, 64]\n",
      "[100, 3]\n",
      "[100, 3, 2]\n",
      "[100, 3, 2, 101]\n",
      "[100, 3, 2, 101, 102]\n",
      "[59, 60]\n",
      "[59, 60, 61]\n",
      "[59, 60, 61, 4]\n",
      "[59, 60, 61, 4, 62]\n",
      "[59, 60, 61, 4, 62, 63]\n",
      "[59, 60, 61, 4, 62, 63, 64]\n",
      "[89, 90]\n",
      "[89, 90, 91]\n",
      "[89, 90, 91, 4]\n",
      "[89, 90, 91, 4, 5]\n",
      "[89, 90, 91, 4, 5, 92]\n",
      "[89, 90, 91, 4, 5, 92, 20]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2, 94]\n",
      "[100, 3]\n",
      "[100, 3, 2]\n",
      "[100, 3, 2, 101]\n",
      "[100, 3, 2, 101, 102]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[95, 13]\n",
      "[95, 13, 10]\n",
      "[95, 13, 10, 96]\n",
      "[95, 13, 10, 96, 97]\n",
      "[95, 13, 10, 96, 97, 98]\n",
      "[95, 13, 10, 96, 97, 98, 99]\n",
      "[109, 110]\n",
      "[109, 110, 1]\n",
      "[109, 110, 1, 111]\n",
      "[109, 110, 1, 111, 7]\n",
      "[109, 110, 1, 111, 7, 112]\n",
      "[109, 110, 1, 111, 7, 112, 113]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[2, 103]\n",
      "[2, 103, 19]\n",
      "[2, 103, 19, 12]\n",
      "[2, 103, 19, 12, 104]\n",
      "[2, 103, 19, 12, 104, 105]\n",
      "[2, 103, 19, 12, 104, 105, 106]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107, 108]\n",
      "[65, 66]\n",
      "[65, 66, 67]\n",
      "[65, 66, 67, 68]\n",
      "[65, 66, 67, 68, 69]\n",
      "[65, 66, 67, 68, 69, 70]\n",
      "[2, 71]\n",
      "[2, 71, 72]\n",
      "[2, 71, 72, 73]\n",
      "[2, 71, 72, 73, 20]\n",
      "[2, 71, 72, 73, 20, 7]\n",
      "[2, 71, 72, 73, 20, 7, 74]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1, 75]\n",
      "[8, 2]\n",
      "[8, 2, 114]\n",
      "[8, 2, 114, 115]\n",
      "[8, 2, 114, 115, 116]\n",
      "[8, 2, 114, 115, 116, 3]\n",
      "[8, 2, 114, 115, 116, 3, 5]\n",
      "[8, 2, 114, 115, 116, 3, 5, 9]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[95, 13]\n",
      "[95, 13, 10]\n",
      "[95, 13, 10, 96]\n",
      "[95, 13, 10, 96, 97]\n",
      "[95, 13, 10, 96, 97, 98]\n",
      "[95, 13, 10, 96, 97, 98, 99]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[65, 66]\n",
      "[65, 66, 67]\n",
      "[65, 66, 67, 68]\n",
      "[65, 66, 67, 68, 69]\n",
      "[65, 66, 67, 68, 69, 70]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[76, 10]\n",
      "[76, 10, 36]\n",
      "[76, 10, 36, 17]\n",
      "[76, 10, 36, 17, 77]\n",
      "[76, 10, 36, 17, 77, 7]\n",
      "[76, 10, 36, 17, 77, 7, 78]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79, 80]\n",
      "[36, 122]\n",
      "[36, 122, 2]\n",
      "[36, 122, 2, 123]\n",
      "[36, 122, 2, 123, 3]\n",
      "[36, 122, 2, 123, 3, 124]\n",
      "[36, 122, 2, 123, 3, 124, 125]\n",
      "[109, 110]\n",
      "[109, 110, 1]\n",
      "[109, 110, 1, 111]\n",
      "[109, 110, 1, 111, 7]\n",
      "[109, 110, 1, 111, 7, 112]\n",
      "[109, 110, 1, 111, 7, 112, 113]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[89, 90]\n",
      "[89, 90, 91]\n",
      "[89, 90, 91, 4]\n",
      "[89, 90, 91, 4, 5]\n",
      "[89, 90, 91, 4, 5, 92]\n",
      "[89, 90, 91, 4, 5, 92, 20]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2, 94]\n",
      "[2, 103]\n",
      "[2, 103, 19]\n",
      "[2, 103, 19, 12]\n",
      "[2, 103, 19, 12, 104]\n",
      "[2, 103, 19, 12, 104, 105]\n",
      "[2, 103, 19, 12, 104, 105, 106]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107, 108]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[89, 90]\n",
      "[89, 90, 91]\n",
      "[89, 90, 91, 4]\n",
      "[89, 90, 91, 4, 5]\n",
      "[89, 90, 91, 4, 5, 92]\n",
      "[89, 90, 91, 4, 5, 92, 20]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2, 94]\n",
      "[2, 103]\n",
      "[2, 103, 19]\n",
      "[2, 103, 19, 12]\n",
      "[2, 103, 19, 12, 104]\n",
      "[2, 103, 19, 12, 104, 105]\n",
      "[2, 103, 19, 12, 104, 105, 106]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107]\n",
      "[2, 103, 19, 12, 104, 105, 106, 1, 107, 108]\n",
      "[65, 66]\n",
      "[65, 66, 67]\n",
      "[65, 66, 67, 68]\n",
      "[65, 66, 67, 68, 69]\n",
      "[65, 66, 67, 68, 69, 70]\n",
      "[76, 10]\n",
      "[76, 10, 36]\n",
      "[76, 10, 36, 17]\n",
      "[76, 10, 36, 17, 77]\n",
      "[76, 10, 36, 17, 77, 7]\n",
      "[76, 10, 36, 17, 77, 7, 78]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79, 80]\n",
      "[109, 110]\n",
      "[109, 110, 1]\n",
      "[109, 110, 1, 111]\n",
      "[109, 110, 1, 111, 7]\n",
      "[109, 110, 1, 111, 7, 112]\n",
      "[109, 110, 1, 111, 7, 112, 113]\n",
      "[95, 13]\n",
      "[95, 13, 10]\n",
      "[95, 13, 10, 96]\n",
      "[95, 13, 10, 96, 97]\n",
      "[95, 13, 10, 96, 97, 98]\n",
      "[95, 13, 10, 96, 97, 98, 99]\n",
      "[8, 2]\n",
      "[8, 2, 114]\n",
      "[8, 2, 114, 115]\n",
      "[8, 2, 114, 115, 116]\n",
      "[8, 2, 114, 115, 116, 3]\n",
      "[8, 2, 114, 115, 116, 3, 5]\n",
      "[8, 2, 114, 115, 116, 3, 5, 9]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[81, 14]\n",
      "[81, 14, 8]\n",
      "[81, 14, 8, 82]\n",
      "[81, 14, 8, 82, 83]\n",
      "[81, 14, 8, 82, 83, 18]\n",
      "[81, 14, 8, 82, 83, 18, 2]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88, 9]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[100, 3]\n",
      "[100, 3, 2]\n",
      "[100, 3, 2, 101]\n",
      "[100, 3, 2, 101, 102]\n",
      "[95, 13]\n",
      "[95, 13, 10]\n",
      "[95, 13, 10, 96]\n",
      "[95, 13, 10, 96, 97]\n",
      "[95, 13, 10, 96, 97, 98]\n",
      "[95, 13, 10, 96, 97, 98, 99]\n",
      "[100, 3]\n",
      "[100, 3, 2]\n",
      "[100, 3, 2, 101]\n",
      "[100, 3, 2, 101, 102]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[109, 110]\n",
      "[109, 110, 1]\n",
      "[109, 110, 1, 111]\n",
      "[109, 110, 1, 111, 7]\n",
      "[109, 110, 1, 111, 7, 112]\n",
      "[109, 110, 1, 111, 7, 112, 113]\n",
      "[2, 71]\n",
      "[2, 71, 72]\n",
      "[2, 71, 72, 73]\n",
      "[2, 71, 72, 73, 20]\n",
      "[2, 71, 72, 73, 20, 7]\n",
      "[2, 71, 72, 73, 20, 7, 74]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1, 75]\n",
      "[2, 71]\n",
      "[2, 71, 72]\n",
      "[2, 71, 72, 73]\n",
      "[2, 71, 72, 73, 20]\n",
      "[2, 71, 72, 73, 20, 7]\n",
      "[2, 71, 72, 73, 20, 7, 74]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1]\n",
      "[2, 71, 72, 73, 20, 7, 74, 1, 75]\n",
      "[37, 11]\n",
      "[37, 11, 38]\n",
      "[37, 11, 38, 7]\n",
      "[37, 11, 38, 7, 39]\n",
      "[37, 11, 38, 7, 39, 40]\n",
      "[37, 11, 38, 7, 39, 40, 41]\n",
      "[8, 2]\n",
      "[8, 2, 114]\n",
      "[8, 2, 114, 115]\n",
      "[8, 2, 114, 115, 116]\n",
      "[8, 2, 114, 115, 116, 3]\n",
      "[8, 2, 114, 115, 116, 3, 5]\n",
      "[8, 2, 114, 115, 116, 3, 5, 9]\n",
      "[117, 21]\n",
      "[117, 21, 118]\n",
      "[117, 21, 118, 119]\n",
      "[117, 21, 118, 119, 120]\n",
      "[117, 21, 118, 119, 120, 3]\n",
      "[117, 21, 118, 119, 120, 3, 121]\n",
      "[117, 21, 118, 119, 120, 3, 121, 30]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[76, 10]\n",
      "[76, 10, 36]\n",
      "[76, 10, 36, 17]\n",
      "[76, 10, 36, 17, 77]\n",
      "[76, 10, 36, 17, 77, 7]\n",
      "[76, 10, 36, 17, 77, 7, 78]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79, 80]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[15, 42]\n",
      "[15, 42, 9]\n",
      "[15, 42, 9, 17]\n",
      "[15, 42, 9, 17, 15]\n",
      "[15, 42, 9, 17, 15, 1]\n",
      "[15, 42, 9, 17, 15, 1, 43]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45]\n",
      "[15, 42, 9, 17, 15, 1, 43, 44, 8, 45, 30]\n",
      "[100, 3]\n",
      "[100, 3, 2]\n",
      "[100, 3, 2, 101]\n",
      "[100, 3, 2, 101, 102]\n",
      "[81, 14]\n",
      "[81, 14, 8]\n",
      "[81, 14, 8, 82]\n",
      "[81, 14, 8, 82, 83]\n",
      "[81, 14, 8, 82, 83, 18]\n",
      "[81, 14, 8, 82, 83, 18, 2]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88, 9]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[21, 10]\n",
      "[21, 10, 31]\n",
      "[21, 10, 31, 3]\n",
      "[21, 10, 31, 3, 4]\n",
      "[21, 10, 31, 3, 4, 32]\n",
      "[21, 10, 31, 3, 4, 32, 13]\n",
      "[81, 14]\n",
      "[81, 14, 8]\n",
      "[81, 14, 8, 82]\n",
      "[81, 14, 8, 82, 83]\n",
      "[81, 14, 8, 82, 83, 18]\n",
      "[81, 14, 8, 82, 83, 18, 2]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88, 9]\n",
      "[6, 2]\n",
      "[6, 2, 5]\n",
      "[6, 2, 5, 33]\n",
      "[6, 2, 5, 33, 1]\n",
      "[6, 2, 5, 33, 1, 34]\n",
      "[6, 2, 5, 33, 1, 34, 35]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11]\n",
      "[6, 2, 5, 33, 1, 34, 35, 11, 14]\n",
      "[46, 47]\n",
      "[46, 47, 48]\n",
      "[46, 47, 48, 49]\n",
      "[46, 47, 48, 49, 16]\n",
      "[46, 47, 48, 49, 16, 8]\n",
      "[46, 47, 48, 49, 16, 8, 16]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50]\n",
      "[46, 47, 48, 49, 16, 8, 16, 5, 18, 50, 51]\n",
      "[22, 12]\n",
      "[22, 12, 23]\n",
      "[22, 12, 23, 3]\n",
      "[22, 12, 23, 3, 4]\n",
      "[22, 12, 23, 3, 4, 24]\n",
      "[22, 12, 23, 3, 4, 24, 25]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1]\n",
      "[22, 12, 23, 3, 4, 24, 25, 26, 27, 28, 29, 1, 6]\n",
      "[76, 10]\n",
      "[76, 10, 36]\n",
      "[76, 10, 36, 17]\n",
      "[76, 10, 36, 17, 77]\n",
      "[76, 10, 36, 17, 77, 7]\n",
      "[76, 10, 36, 17, 77, 7, 78]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79]\n",
      "[76, 10, 36, 17, 77, 7, 78, 79, 80]\n",
      "[89, 90]\n",
      "[89, 90, 91]\n",
      "[89, 90, 91, 4]\n",
      "[89, 90, 91, 4, 5]\n",
      "[89, 90, 91, 4, 5, 92]\n",
      "[89, 90, 91, 4, 5, 92, 20]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2]\n",
      "[89, 90, 91, 4, 5, 92, 20, 93, 1, 6, 2, 94]\n",
      "[52, 2]\n",
      "[52, 2, 53]\n",
      "[52, 2, 53, 54]\n",
      "[52, 2, 53, 54, 19]\n",
      "[52, 2, 53, 54, 19, 55]\n",
      "[52, 2, 53, 54, 19, 55, 56]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57]\n",
      "[52, 2, 53, 54, 19, 55, 56, 9, 1, 57, 58]\n",
      "[65, 66]\n",
      "[65, 66, 67]\n",
      "[65, 66, 67, 68]\n",
      "[65, 66, 67, 68, 69]\n",
      "[65, 66, 67, 68, 69, 70]\n",
      "[81, 14]\n",
      "[81, 14, 8]\n",
      "[81, 14, 8, 82]\n",
      "[81, 14, 8, 82, 83]\n",
      "[81, 14, 8, 82, 83, 18]\n",
      "[81, 14, 8, 82, 83, 18, 2]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88]\n",
      "[81, 14, 8, 82, 83, 18, 2, 84, 85, 86, 87, 88, 9]\n"
     ]
    }
   ],
   "source": [
    "sequence_data = []\n",
    "for sentence in message:\n",
    "    # print(sentence)\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    # print(tokenized_sentence)\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        seq = tokenized_sentence[:i+1]\n",
    "        print(seq)\n",
    "        sequence_data.append(seq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef60cbd-b531-4ef1-bf1f-1c16e944e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(lst) for lst in sequence_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3aecb65-2e42-4d8e-8b42-7942c70ac309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79458141-e818-4e9b-b5a5-b49ac07953dc",
   "metadata": {},
   "source": [
    "## Finial Enhance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa62574-1765-4298-954f-e087b78868a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d737e8-8bf2-4775-bc9f-806c0fe880d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_sequnces = pad_sequences(sequence_data,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "130d74c2-c84c-4894-ba01-e71e48567719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   2, 103],\n",
       "       [  0,   0,   0, ...,   2, 103,  19],\n",
       "       [  0,   0,   0, ..., 103,  19,  12],\n",
       "       ...,\n",
       "       [  0,   0,  81, ...,  85,  86,  87],\n",
       "       [  0,  81,  14, ...,  86,  87,  88],\n",
       "       [ 81,  14,   8, ...,  87,  88,   9]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequnces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605bdf7f-0384-4173-ab4a-703cff3c9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "###we get our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b750b9-a443-46f1-9207-13b3c269d7f1",
   "metadata": {},
   "source": [
    "## Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f929d1-70e3-4b56-bc93-c70a6b211d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = padded_input_sequnces[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c1077f7-b573-417e-90c4-c03c4e8cb85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c34cc-e53d-4239-858a-cb887e1c1b64",
   "metadata": {},
   "source": [
    "## Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00ae18de-84ae-4369-a2c8-a2a6423a1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = padded_input_sequnces[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e04bb216-264e-41b4-9f6f-e8d040743ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960d0dc9-4406-43c1-9e39-de73ba3ab43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We are create nn so when we enchance the labels by using to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45de13a1-1ee1-4256-865c-f6ea725c5d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 1,\n",
       " 'your': 2,\n",
       " 'for': 3,\n",
       " 'a': 4,\n",
       " 'free': 5,\n",
       " 'claim': 6,\n",
       " 'the': 7,\n",
       " 'get': 8,\n",
       " 'now': 9,\n",
       " 'you': 10,\n",
       " 'time': 11,\n",
       " 'been': 12,\n",
       " 'call': 13,\n",
       " 'offer': 14,\n",
       " 'win': 15,\n",
       " '1': 16,\n",
       " 'send': 17,\n",
       " 'on': 18,\n",
       " 'has': 19,\n",
       " 'click': 20,\n",
       " 'are': 21,\n",
       " 'you’ve': 22,\n",
       " 'selected': 23,\n",
       " '1000': 24,\n",
       " 'walmart': 25,\n",
       " 'gift': 26,\n",
       " 'card': 27,\n",
       " 'reply': 28,\n",
       " 'yes': 29,\n",
       " 'today': 30,\n",
       " 'available': 31,\n",
       " 'quick': 32,\n",
       " 'vacation': 33,\n",
       " 'hawaii': 34,\n",
       " 'limited': 35,\n",
       " 'please': 36,\n",
       " 'what': 37,\n",
       " 'does': 38,\n",
       " 'movie': 39,\n",
       " 'start': 40,\n",
       " 'tonight': 41,\n",
       " 'cash': 42,\n",
       " '88888': 43,\n",
       " 'and': 44,\n",
       " 'lucky': 45,\n",
       " 'lowest': 46,\n",
       " 'prices': 47,\n",
       " 'ever': 48,\n",
       " 'buy': 49,\n",
       " 'all': 50,\n",
       " 'items': 51,\n",
       " 'hurry': 52,\n",
       " 'car': 53,\n",
       " 'insurance': 54,\n",
       " 'expired': 55,\n",
       " 'renew': 56,\n",
       " 'avoid': 57,\n",
       " 'penalty': 58,\n",
       " 'good': 59,\n",
       " 'morning': 60,\n",
       " 'have': 61,\n",
       " 'great': 62,\n",
       " 'day': 63,\n",
       " 'ahead': 64,\n",
       " 'let’s': 65,\n",
       " 'catch': 66,\n",
       " 'up': 67,\n",
       " 'sometime': 68,\n",
       " 'this': 69,\n",
       " 'weekend': 70,\n",
       " 'loan': 71,\n",
       " 'is': 72,\n",
       " 'approved': 73,\n",
       " 'link': 74,\n",
       " 'proceed': 75,\n",
       " 'can': 76,\n",
       " 'me': 77,\n",
       " 'notes': 78,\n",
       " 'from': 79,\n",
       " 'class': 80,\n",
       " 'exclusive': 81,\n",
       " '50': 82,\n",
       " 'off': 83,\n",
       " 'next': 84,\n",
       " 'purchase': 85,\n",
       " 'visit': 86,\n",
       " 'our': 87,\n",
       " 'website': 88,\n",
       " 'congratulations': 89,\n",
       " \"you've\": 90,\n",
       " 'won': 91,\n",
       " 'iphone': 92,\n",
       " 'here': 93,\n",
       " 'prize': 94,\n",
       " 'i’ll': 95,\n",
       " 'once': 96,\n",
       " 'i': 97,\n",
       " 'reach': 98,\n",
       " 'home': 99,\n",
       " 'thanks': 100,\n",
       " 'help': 101,\n",
       " 'yesterday': 102,\n",
       " 'account': 103,\n",
       " 'suspended': 104,\n",
       " 'verify': 105,\n",
       " 'immediately': 106,\n",
       " 'restore': 107,\n",
       " 'access': 108,\n",
       " 'don’t': 109,\n",
       " 'forget': 110,\n",
       " 'bring': 111,\n",
       " 'book': 112,\n",
       " 'tomorrow': 113,\n",
       " 'credit': 114,\n",
       " 'score': 115,\n",
       " 'checked': 116,\n",
       " 'hey': 117,\n",
       " 'we': 118,\n",
       " 'still': 119,\n",
       " 'meeting': 120,\n",
       " 'lunch': 121,\n",
       " 'confirm': 122,\n",
       " 'attendance': 123,\n",
       " 'tomorrow’s': 124,\n",
       " 'event': 125}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7c2af1-b612-498f-9702-c8b35f22c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ec5858-34fd-4631-b74d-4e0f3912d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels,num_classes=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f68b9aa-6b22-47c3-a828-dfaaf36b4598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4ddede8-f12d-4076-81e6-3619046431aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811, 126)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4876235-099d-43fa-bd2e-929800b93923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tokenizer,'tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d6d51-cd94-44c4-a595-d6a2d41b33d9",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d91fb0-830c-4074-9470-045492a15839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2eed07c-88ed-4fa9-800b-3a847055fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abc262ed-819f-4809-b313-23172e2ba77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24f23098-2949-4381-949a-db8ade17cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddeba\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(126,100,input_length = 12))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(126,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2fa72de5-f81b-4ea8-8cd1-a6ac03958da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4908e91c-adb6-491c-bfca-d6df3154a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f72ca117-7746-4405-aef7-e6d3306c13df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,026</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m12,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m)                 │          \u001b[38;5;34m19,026\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,226</span> (711.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m182,226\u001b[0m (711.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,226</span> (711.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m182,226\u001b[0m (711.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b36a969e-45d2-435e-b7c9-eb44886dfd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0407 - loss: 4.7416   \n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0629 - loss: 4.4735\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0777 - loss: 4.1972 \n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1344 - loss: 3.7772 \n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2035 - loss: 3.3206 \n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3046 - loss: 2.8254 \n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4353 - loss: 2.3810 \n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5771 - loss: 1.9667\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6769 - loss: 1.6428 \n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7361 - loss: 1.3814 \n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8002 - loss: 1.1668 \n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8582 - loss: 0.9693 \n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9088 - loss: 0.8210 \n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9371 - loss: 0.6916 \n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9556 - loss: 0.5787 \n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9655 - loss: 0.4959\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.4213 \n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.3635 \n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.3076 \n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.2676 \n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.2412 \n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.2050 \n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.1855 \n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.1607 \n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.1437 \n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.1295\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.1194 \n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.1072 \n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0972 \n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0896 \n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0832 \n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0758 \n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0704 \n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0656 \n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0613 \n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0574 \n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0537 \n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0510 \n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0481\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0462\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0434 \n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0414 \n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0396 \n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0376 \n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0366 \n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0345 \n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0334\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0333 \n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0309 \n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0299 \n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0294\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0274 \n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0270 \n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0267 \n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0250 \n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0244 \n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0238\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0233\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0230 \n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0217 \n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0215 \n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0212 \n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0210 \n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0200 \n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0202 \n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0189 \n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0185 \n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0186 \n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0178\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0180 \n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0175\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0170 \n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0170\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0167\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0167 \n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0161 \n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0158 \n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0163 \n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0161\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0154 \n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0150 \n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0144\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0143 \n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0146 \n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0141 \n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0142 \n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0138 \n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0134\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0141 \n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0133 \n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0138\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0141 \n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0132\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0131 \n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0128 \n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0128 \n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0130 \n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0124 \n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0128\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bb846ac830>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(feature,labels,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "638b253d-eb82-4bd1-9a02-a15bc045a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 103]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa04a113-c1c9-40e4-ab3a-4fda05f00ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "has\n"
     ]
    }
   ],
   "source": [
    "text2 = 'Your account'\n",
    "text_sequence = tokenizer.texts_to_sequences([text2])[0]\n",
    "padded_text_sequence = pad_sequences([text_sequence],maxlen=max_len,padding='pre')\n",
    "predictionn = model.predict(padded_text_sequence)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pos = np.argmax(predictionn)\n",
    "for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "        print(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "04f28a98-22e7-41ec-b1c0-8a99b55dc60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nxt-model.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'nxt-model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "161460c8-97e1-4818-bc16-84038b2d94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = joblib.load('nxt-model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b5bcfb34-fb9c-41d2-accc-71f9510aeb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370173b39b3e49819d15ddfc3bd159fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Text:', placeholder='Type something...'), HTML(value='<b>Prediction…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install ipywidgets --quiet\n",
    "from ipywidgets import Text, HTML, VBox\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ---------------------------\n",
    "# YOUR PREDICTION FUNCTION\n",
    "# ---------------------------\n",
    "def predict_next_word(input_text):\n",
    "\n",
    "    # Convert text → tokens\n",
    "    token_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "\n",
    "    # Pad the sequence (same as your model)\n",
    "    sequence_text = pad_sequences([token_text], maxlen=24, padding='pre')\n",
    "\n",
    "    # Predict\n",
    "    prediction = model_0.predict(sequence_text, verbose=0)\n",
    "\n",
    "    # Get the word with highest probability\n",
    "    pos = np.argmax(prediction)\n",
    "\n",
    "    # Find the word from tokenizer\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "            return word\n",
    "\n",
    "    return \"(no prediction)\"\n",
    "\n",
    "# ---------------------------\n",
    "# INTERACTIVE TEXTBOX UI       ######### Lucky is here don't worry about any kind of problem #########\n",
    "# ---------------------------\n",
    "textbox = Text(\n",
    "    value='',\n",
    "    placeholder='Type something...',\n",
    "    description='Text:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "output = HTML(value=\"<b>Prediction:</b> (type something)\")\n",
    "\n",
    "# Auto-update function\n",
    "def on_text_change(change):\n",
    "    text = change[\"new\"]\n",
    "    next_word = predict_next_word(text)\n",
    "    output.value = f\"<b>Prediction:</b> {next_word}\"\n",
    "\n",
    "textbox.observe(on_text_change, names='value')\n",
    "\n",
    "# Display UI ### \n",
    "display(VBox([textbox, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7692707-8c7e-45c1-96c7-08685c8cfca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
